<img src="./docs/banner.webp" alt="Contextinator" width="100%" />
<br />
<h1 align="center">Contextinator <img src="./docs/0banner.png" alt="Contextinator" width="30" /></h1>
<p align="center">
The weapon of mass codebase context for agentic AI. <br />
Turn any codebase into semantically-aware, searchable knowledge for AI-powered workflows.
</p>


---

## üìñ Overview

**Contextinator** is a powerful tool that bridges the gap between static codebases and intelligent AI agents. It uses Abstract Syntax Tree (AST) parsing to extract semantic code chunks, generates embeddings, and stores them in a vector database-enabling AI agents to understand, navigate, and reason about codebases with unprecedented precision.

### ‚ú® Key Features

- üå≥ **AST-Powered Chunking** - Extract functions, classes, and methods from 23+ programming languages
- üîç **Semantic Search** - Find relevant code using natural language queries
- üöÄ **Full Pipeline Automation** - One command to chunk, embed, and store
- üéØ **Smart Deduplication** - Hash-based detection of duplicate code
- üìä **Visual AST Explorer** - Debug and visualize code structure
- üì¶ **TOON Format Export** - Token-efficient output format for LLM prompts (40-60% savings)

- üê≥ **Docker-Ready** - ChromaDB server included

### üéØ Use Cases

- **AI Code Assistants** - Give LLMs deep codebase understanding
- **Documentation Generation** - Auto-generate docs from code structure
- **Code Search & Discovery** - Find implementations across large projects
- **Refactoring Analysis** - Identify duplicate or similar code patterns
- **Onboarding Automation** - Help new developers navigate unfamiliar codebases

---

## ‚ö†Ô∏è Warning

all the content below this line is generated by AI and may contain inaccuracies. Project is still under active development and things may change rapidly. Please refer to the source code for the most up-to-date information.

## üöÄ Quick Start

### Prerequisites

- Python 3.11 or higher
- Docker (for ChromaDB)
- OpenAI API key (for embeddings)

### Installation

**Step 1:** Clone and setup

```bash
git clone https://github.com/starthackHQ/Contextinator.git
cd Contextinator
```

**Step 2:** Create virtual environment

```bash
python -m venv .venv
```

**Step 3:** Activate environment

```bash
# Windows
.venv\Scripts\activate

# macOS/Linux
source .venv/bin/activate
```

**Step 4:** Install dependencies

```bash
pip install -r requirements.txt
```

**Step 5:** Configure environment

Create a `.env` file:

```bash
OPENAI_API_KEY=your_openai_api_key_here
USE_CHROMA_SERVER=true
CHROMA_SERVER_URL=http://localhost:8000
```

**Step 6:** Start ChromaDB

```bash
docker-compose up -d
```

# Usage

this can be used in 2 ways, either via the CLI or programmatically via python code.

## CLI
**Usage:** `python -m src.contextinator.cli <command> [options]`
### 1. Chunking

```bash
python -m src.contextinator.cli chunk --save --path <repo-path> --output <output-dir>
python -m src.contextinator.cli chunk --save --repo-url <github-url>
python -m src.contextinator.cli chunk --save-ast  # Save AST trees for debugging
python -m src.contextinator.cli chunk --chunks-dir <custom-dir>  # Custom chunks directory
```

### 2. Embedding
right now, we're only supporting OpenAI embeddings, so make sure you've got the `.env.example` setup'd correctly.

```bash
python -m src.contextinator.cli embed --save --path <repo-path> --output <output-dir>
python -m src.contextinator.cli embed --save --repo-url <github-url>
python -m src.contextinator.cli embed --chunks-dir <custom-dir> --embeddings-dir <custom-dir>
```

### 3. Storing in Vector Store
**Note:** Make sure ChromaDB server is running: `docker-compose up -d`
```bash
python -m src.contextinator.cli store-embeddings --path <repo-path> --output <output-dir>
python -m src.contextinator.cli store-embeddings --collection-name <custom-name>
python -m src.contextinator.cli store-embeddings --repo-name <repo-name> --collection-name <custom-name>
python -m src.contextinator.cli store-embeddings --embeddings-dir <custom-dir> --chromadb-dir <custom-dir>
```

### 4. Search Tools
z
```bash
# Semantic search
python -m src.contextinator.cli search "your query" --collection <name> -n 5

# Symbol search
python -m src.contextinator.cli symbol <function/class-name> --collection <name>

# Pattern/regex search
python -m src.contextinator.cli pattern "pattern" --collection <name>

# Read complete file
python -m src.contextinator.cli read-file <file-path> --collection <name>

# Advanced search

# Export results in TOON format (40-60% token savings for LLMs)
python -m src.contextinator.cli search "query" --collection <name> --toon results.json
python -m src.contextinator.cli symbol <name> --collection <name> --toon symbols.json
python -m src.contextinator.cli search-advanced --collection <name> --semantic "query" --language python
```

### 5. Combined Pipeline

```bash
# Chunk + Embed + Store (all-in-one)
python -m src.contextinator.cli chunk-embed-store-embeddings --save --path <repo-path> --output <output-dir>
python -m src.contextinator.cli chunk-embed-store-embeddings --save --repo-url <github-url> --collection-name <name>
python -m src.contextinator.cli chunk-embed-store-embeddings --chunks-dir <dir> --embeddings-dir <dir> --chromadb-dir <dir>
```

### Database Management

```bash
python -m src.contextinator.cli db-info           # Show database stats
python -m src.contextinator.cli db-list           # List all collections
python -m src.contextinator.cli db-show <name>    # Show collection details
python -m src.contextinator.cli db-clear <name>   # Delete collection
python -m src.contextinator.cli db-info --chromadb-dir <custom-dir>  # Use custom ChromaDB location
python -m src.contextinator.cli db-info --repo-name <repo-name>      # Use specific repo database
```

**Default Storage:** Files are saved to `.contextinator/chunks/`, `.contextinator/embeddings/`, and `.contextinator/chromadb/` directories.

**Custom Directories:** Use `--chunks-dir`, `--embeddings-dir`, or `--chromadb-dir` to override default locations.

## Typical Workflow

```bash
# 1. Chunk a repository
python -m src.contextinator.cli chunk --repo-url https://github.com/user/repo --save

# 2. Generate embeddings  
python -m src.contextinator.cli embed --repo-url https://github.com/user/repo --save

# 3. Store in vector database
python -m src.contextinator.cli store-embeddings --repo-name repo --collection-name MyRepo

# Or do all steps at once
python -m src.contextinator.cli chunk-embed-store-embeddings --repo-url https://github.com/user/repo --save --collection-name MyRepo
```


